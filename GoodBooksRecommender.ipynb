{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKI2enGN0VY8wThboYYVM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kakashi3lite/GoodBooksRecommender/blob/main/GoodBooksRecommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "1cEsFbpUPVC5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNkz-iWESyk8",
        "outputId": "e3cc9a32-d852-490f-f021-f42777540fc4"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_path = '/content/drive/My Drive/Goodbooks/books.csv'\n",
        "ratings_path = '/content/drive/My Drive/Goodbooks/ratings.csv'\n",
        "tags_path = '/content/drive/My Drive/Goodbooks/tags.csv'\n",
        "book_tags_path = '/content/drive/My Drive/Goodbooks/book_tags.csv'\n"
      ],
      "metadata": {
        "id": "3V77SOFbS7IW"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load and Merge Data"
      ],
      "metadata": {
        "id": "atsaaUOASW0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_merge_data(books_path, ratings_path, tags_path, book_tags_path):\n",
        "    # Load datasets\n",
        "    books = pd.read_csv(books_path)\n",
        "    ratings = pd.read_csv(ratings_path)\n",
        "    tags = pd.read_csv(tags_path)\n",
        "    book_tags = pd.read_csv(book_tags_path)\n",
        "\n",
        "    # Merge books with tags using book_id\n",
        "    book_tags = book_tags.merge(tags, on='tag_id', how='left')\n",
        "    books = books.merge(book_tags, left_on='goodreads_book_id', right_on='goodreads_book_id', how='left')\n",
        "\n",
        "    return books, ratings"
      ],
      "metadata": {
        "id": "IpxrCB4rSUi3"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Preprocess the Data"
      ],
      "metadata": {
        "id": "_nbz95OzSgBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(books):\n",
        "    # Combine all tag names for each book into a single string\n",
        "    books['all_tags'] = books.groupby('book_id')['tag_name'].transform(lambda x: ' '.join(x.dropna()))\n",
        "    books = books.drop_duplicates(subset='book_id')  # Remove duplicates\n",
        "    books.loc[:, 'all_tags'] = books['all_tags'].fillna('')  # Use .loc to avoid warnings\n",
        "  # Fill missing values with an empty string\n",
        "    return books"
      ],
      "metadata": {
        "id": "WvZi0RWyTxq0"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Building the TF-IDF Matrix"
      ],
      "metadata": {
        "id": "_zSlXXl1T1Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tfidf_matrix(books):\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(books['all_tags'])\n",
        "    return tfidf_matrix"
      ],
      "metadata": {
        "id": "NRVwpd-mT5Hu"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Computing Cosine Similarity"
      ],
      "metadata": {
        "id": "SGCUVXCFT7Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity(tfidf_matrix):\n",
        "    return cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ],
      "metadata": {
        "id": "zg2LkuIST-GJ"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Building Recommendation Function"
      ],
      "metadata": {
        "id": "20jRl1qxUAGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_books(book_title, books, cosine_sim):\n",
        "    try:\n",
        "        # Debug: Print all available titles\n",
        "        print(\"Available titles for matching:\")\n",
        "        print(books['title'].head(20))  # Print a subset of titles for debugging\n",
        "\n",
        "        # Use case-insensitive, stripped matching\n",
        "        matched_books = books[books['title'].str.strip().str.contains(book_title.strip(), case=False, na=False)]\n",
        "\n",
        "        # Debug: Print matched books\n",
        "        print(f\"Matched books for '{book_title}':\")\n",
        "        print(matched_books[['title', 'authors']].head())\n",
        "\n",
        "        if matched_books.empty:\n",
        "            return f\"Book titled '{book_title}' not found! Please try another title.\"\n",
        "\n",
        "        # Use the first match's index\n",
        "        idx = matched_books.index[0]\n",
        "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        sim_scores = sim_scores[1:4]  # Top 3 recommendations\n",
        "        book_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "        # Debug: Print recommended indices\n",
        "        print(\"Recommended indices and scores:\")\n",
        "        print(sim_scores)\n",
        "\n",
        "        return books.iloc[book_indices][['title', 'authors', 'average_rating']]\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\""
      ],
      "metadata": {
        "id": "9ntG9y_6UEOz"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Specify dataset paths\n",
        "    books_path = \"/content/drive/My Drive/Goodbooks/books.csv\"\n",
        "    ratings_path = \"/content/drive/My Drive/Goodbooks/ratings.csv\"\n",
        "    tags_path = \"/content/drive/My Drive/Goodbooks/tags.csv\"\n",
        "    book_tags_path = \"/content/drive/My Drive/Goodbooks/book_tags.csv\"\n",
        "\n",
        "    # Load and preprocess the data\n",
        "    books, ratings = load_and_merge_data(books_path, ratings_path, tags_path, book_tags_path)\n",
        "    books = preprocess_data(books)\n",
        "\n",
        "    # Debug: Print number of unique titles\n",
        "    print(f\"Number of unique titles: {books['title'].nunique()}\")\n",
        "\n",
        "    # Build the TF-IDF matrix and compute similarity\n",
        "    tfidf_matrix = build_tfidf_matrix(books)\n",
        "    cosine_sim = compute_similarity(tfidf_matrix)\n",
        "\n",
        "    # Test the recommendation system\n",
        "    test_book = 'Atomic Habits'  # Replace with a book title for testing\n",
        "    recommendations = recommend_books(test_book, books, cosine_sim)\n",
        "\n",
        "    print(f\"Recommendations for '{test_book}':\")\n",
        "    if isinstance(recommendations, str):\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        print(recommendations.to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka65dnXAW0qd",
        "outputId": "bf590b87-7753-4aac-b876-54cc9d50e7f8"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique titles: 9964\n",
            "Available titles for matching:\n",
            "0                 The Hunger Games (The Hunger Games, #1)\n",
            "100     Harry Potter and the Sorcerer's Stone (Harry P...\n",
            "200                               Twilight (Twilight, #1)\n",
            "300                                 To Kill a Mockingbird\n",
            "400                                      The Great Gatsby\n",
            "500                                The Fault in Our Stars\n",
            "600                                            The Hobbit\n",
            "700                                The Catcher in the Rye\n",
            "800                 Angels & Demons  (Robert Langdon, #1)\n",
            "900                                   Pride and Prejudice\n",
            "1000                                      The Kite Runner\n",
            "1100                            Divergent (Divergent, #1)\n",
            "1200                                                 1984\n",
            "1300                                          Animal Farm\n",
            "1400                            The Diary of a Young Girl\n",
            "1500     The Girl with the Dragon Tattoo (Millennium, #1)\n",
            "1600                 Catching Fire (The Hunger Games, #2)\n",
            "1700    Harry Potter and the Prisoner of Azkaban (Harr...\n",
            "1800    The Fellowship of the Ring (The Lord of the Ri...\n",
            "1900                    Mockingjay (The Hunger Games, #3)\n",
            "Name: title, dtype: object\n",
            "Matched books for 'Atomic Habits':\n",
            "Empty DataFrame\n",
            "Columns: [title, authors]\n",
            "Index: []\n",
            "Recommendations for 'Atomic Habits':\n",
            "Book titled 'Atomic Habits' not found! Please try another title.\n"
          ]
        }
      ]
    }
  ]
}
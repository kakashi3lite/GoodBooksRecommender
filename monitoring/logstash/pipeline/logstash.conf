input {
  # Read application logs from files
  file {
    path => "/app/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    tags => ["application"]
  }
  
  # Listen for logs from applications via TCP
  tcp {
    port => 5000
    codec => json
    tags => ["tcp"]
  }
  
  # Listen for logs from applications via UDP
  udp {
    port => 5000
    codec => json
    tags => ["udp"]
  }
  
  # Beats input for structured logging
  beats {
    port => 5044
    tags => ["beats"]
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # Add timestamp parsing
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
  
  # Parse log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }
  
  # Extract correlation ID
  if [correlation_id] {
    mutate {
      add_field => { "trace_id" => "%{correlation_id}" }
    }
  }
  
  # Grok patterns for various log formats
  if "application" in [tags] {
    if [path] =~ /access\.log/ {
      grok {
        match => { 
          "message" => "%{COMBINEDAPACHELOG}" 
        }
        tag_on_failure => ["_grokparsefailure_access"]
      }
      
      if [response] {
        mutate {
          convert => { "response" => "integer" }
        }
      }
      
      if [bytes] {
        mutate {
          convert => { "bytes" => "integer" }
        }
      }
      
      mutate {
        add_field => { "log_type" => "access" }
      }
    }
    
    else if [path] =~ /error\.log/ {
      mutate {
        add_field => { "log_type" => "error" }
      }
    }
    
    else if [path] =~ /performance\.log/ {
      mutate {
        add_field => { "log_type" => "performance" }
      }
      
      # Extract performance metrics
      if [duration_ms] {
        mutate {
          convert => { "duration_ms" => "float" }
        }
      }
    }
    
    else {
      mutate {
        add_field => { "log_type" => "application" }
      }
    }
  }
  
  # Security log processing
  if [security_log] {
    mutate {
      add_field => { "log_type" => "security" }
      add_tag => ["security"]
    }
    
    # Extract IP addresses for security analysis
    if [message] =~ /\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b/ {
      grok {
        match => { 
          "message" => "%{IP:client_ip}" 
        }
      }
    }
  }
  
  # Audit log processing
  if [audit_log] {
    mutate {
      add_field => { "log_type" => "audit" }
      add_tag => ["audit"]
    }
  }
  
  # ML/Model performance logs
  if [component] == "ml_pipeline" {
    mutate {
      add_field => { "log_type" => "ml_performance" }
      add_tag => ["ml", "performance"]
    }
  }
  
  # Add geographic information for IP addresses
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
  
  # Parse user agent
  if [agent] {
    useragent {
      source => "agent"
      target => "user_agent"
    }
  }
  
  # Calculate response time categories
  if [duration_ms] {
    if [duration_ms] <= 100 {
      mutate { add_field => { "response_time_category" => "fast" } }
    } else if [duration_ms] <= 500 {
      mutate { add_field => { "response_time_category" => "normal" } }
    } else if [duration_ms] <= 2000 {
      mutate { add_field => { "response_time_category" => "slow" } }
    } else {
      mutate { add_field => { "response_time_category" => "very_slow" } }
    }
  }
  
  # Add environment and service tags
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:development}"
      "service_name" => "goodbooks-recommender"
    }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "tags" ]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "goodbooks-logs-%{+YYYY.MM.dd}"
    template_name => "goodbooks"
    template => "/usr/share/logstash/config/goodbooks-template.json"
    template_overwrite => true
  }
  
  # Debug output for development
  if [environment] == "development" {
    stdout { 
      codec => rubydebug 
    }
  }
  
  # Output critical errors to dedicated index
  if [level] == "CRITICAL" or [level] == "ERROR" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "goodbooks-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # Output security events to dedicated index
  if "security" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "goodbooks-security-%{+YYYY.MM.dd}"
    }
  }
  
  # Output audit events to dedicated index
  if "audit" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "goodbooks-audit-%{+YYYY.MM.dd}"
    }
  }
  
  # Output performance metrics to dedicated index
  if [log_type] == "performance" or [log_type] == "ml_performance" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "goodbooks-performance-%{+YYYY.MM.dd}"
    }
  }
}
